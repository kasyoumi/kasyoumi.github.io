---
tag:
- article
- blog
- concurrent
creation date: 2024-01-26 15:59
name: "how to do safe concurrent programming"
title: "怎样安全的并发编程"
lastmod date: 2024-02-26 22:56
description: "我们仍未确定那天所见变量的状态"

description: 我们仍未确定那天所见变量的状态
date: 2024-02-29
lastmod: 2024-02-29 23:36
toc: true
isCJKLanguage: true
keywords:
  - zonowry
  - 怎样安全的并发编程
  - concurrent
  - threads
  - 并发
  - 反应式
  - 协程
  - coroutine
  - reactive
---

## 引言

说到并发，首先会想到多线程。若只关注多线程如何使用，却对并发编程没有深入的了解，很容易在代码里挖坑，变成这个段子的模样：“从前有个程序员遇到了一个性能问题。他想，没事，我懂，用线程就好了。现他有在个两题了问“。

为了避免这种情况，我们该思考“为什么需要多线程，为什么 `js` 里没有多线程？”等诸类问题。将多线程看成是并发的一种手段，也就是让我们往下面 （the lower）走一点，越过线程理解并发编程。

> 如果逻辑控制流在时间上重叠，那么它们就是**并发的**（concurrent）—— 《CSAPP》

## 理论指导实践

分析 `thread（线程）`、`coroutine（协程）`、`reactive（反应式）`、`event/task queue（任务队列）`等各种并发**手段**。不讨论它们的用法、优劣，而是关注它们的的相似之处——它们实际都是通过编排、调度**逻辑控制流**实现的并发。所以只需要搞清楚它们是如何调度**执行单元**的，就掌握了核心~~科技~~。

> 逻辑控制流，底层一点的理解是硬件电路形成的一组逻辑。应用级一点的解释是一个可以被执行的内容，可能是线程、协程、一个可观察对象 Observable、Subscription、FutureTask、Event Callback......等等。不过用 `CSAPP` 书中的**逻辑控制流**表示一个可执行内容有点极简，所以下文就称之（you know it）为**任务**或**执行单元**吧，**代表一个可被执行的片段**。

### 抢占式调度

首先是最常见的抢占式调度，执行单元间呈**竞争**关系，A 任务与 B 任务互相争夺执行机会。最常见的例子是“操作系统内核利用 CPU 时钟中断，达成多线程并发“。每次中断都代表某个线程抢到了 CPU 时间片”。因为 CPU 中断是纳秒级的，实际效果是内核在飞快的切换执行单元以交错执行。提供一种所有线程在**并行**的假象。在多核心 CPU 下，内核的抢占式调度也足以实现真正的**并行**。

抢占式调度下，执行单元无法确定自己什么时候会被执行，且任何时刻都可能会被中断执行。反过来说，只要我们基于此特性，处理好执行单元的竞争与中断，就可以实现一个抢占式调度器。也可以看出抢占式调度的好处是不会存在独占情况——某个执行单元永远占用着 CPU。因为每个执行单元都有被执行的机会，就像在等红绿灯一样。

### 协作式调度

协作式调度可以引出一大堆技术，例如 `IO 多路复用` 、`迭代器`、`事件驱动` 等等。

它们都有一个点——主动让渡控制权，或者说主动挂起的（释放并等待）。A 任务与 B 任务可以在**合适**的时机**主动**让渡出控制权。特点是持有控制权的任务主动中断，~~抛开现实不谈（例如 CPU 中断），~~这也突出了协作式调度的优点与理念——“调度不会影响**顺序性**“。因为我们是主动让出的，继续执行时可以找到让渡时的节点来保证顺序性，也可以理解为调度器会帮我们将执行单元恢复到让渡前一刻的状态，然后就像没让渡过一样继续执行。

协作式调度，执行单元知道自己什么时候会让出，但同时对程序员也是**无感知**的，因为当再次拿到控制权时，协作式调度器可以保持顺序性[^注：顺序性]。这个特性提高了程序员们的并发编程体验。于是出现了很多协作式调度框架。抽象的角度看，不论是 `Reactive Stream`，还是 `coroutine` ，在我看来都是协作式调度的不同实现。它们都有着执行单元可以主动挂起的特性，与其它执行单元**协作式**的完成逻辑。

## 实践中的问题

是时候为线程正名一下了，虽然前面段落不适合提及线程，但现在线程必不可少，因为线程作为系统内核最小的调度单位，实现**并行**基本[^注：单线程并行]离不开线程。协程、反应式等用户态的并发模型到底还是跑在线程上的。

单线程的话，就不存在着并发编程中的问题，无非就是线程安全了。原因只有**并发环境下访问共享可变的状态**一种。但为什么**共享状态**这个操作会引起问题？因为数据读写不一致。为什么会读写不一致？需要搞清楚并发下计算机是如何读写状态的。

> 专业一点的说共享状态就是**竞态条件**。也说明两个执行单元可能有某种依赖关系，它们需要协商好谁可以使用这个状态。

### 缓存一致性

假设计算机的内存**非常快**且**非常大**，那我们就不需要担心**缓存一致性**问题了，为什么？因为每次读取状态，都是最新的状态，这是纳秒级实时读写。~~（最后说一次，时间要加速了）~~，这是美好的未来。可现实世界的计算机是有极限的（~~我不做电子计算机了！JOJO！~~），计算机的妥协设计是每个 CPU 核心都有一块**独立的**非常快，但非常小的内存，称之为**高速缓存**；再加一块速度尚可（远不及 CPU 计算速度），但非常大的内存，它就是我们的内存条，称之为**主内存**。

两块内存特性互补，让数据读写不至于拖慢 CPU 计算。妥协的代价就是数据一致性问题，或者说数据可见性问题。因为 cpu 运行一个线程时，需要先从主内存读取数据拷贝到高速缓存里，之后就是 cpu 与高速缓存的时间了，期间 CPU 会适时的将高速缓存里的堆积数据刷写到主内存中。问题出在线程间可以共享数据，会牵扯到**数据同步**（~~最小的分布式了吧？~~），有数据同步就不可避免的有一致性问题了，与分布式、数据库领域的**数据一致性**大同小异。

高级语言为了避免我们太操心这些事情，抽象了运行时内存区域（堆栈、常量区、方法区...），然后设计了内存模型，负责线程间通信，保证线程间数据同步，线程空间隔离。让多线程容易使用，程序员们要操心的事情变少了（不用和系统底层打交道），但也也让线程间通信变的陷阱重重。

### 读写有序性

不考虑性能，假设不存在中间**缓存**，每个 CPU 核心实时读写主内存，可以保证所有线程共享数据的**一致性**，就像 `java` 中 `volatile`、数据库的 `读已提交` 事务级别。但这样能解决线程安全问题吗？还是不行，因为计算机并不会 `line by line` 的执行代码，因为计算机/虚拟机会在不影响语义的情况下，优化代码的执行顺序。也就是优化后应该与不优化执行的结果一致，称之为**重排序**。

**多个线程**只共享**一个变量**时，`volatile` 或者我们的假设确实有用，指令重排序对我们来说不会是问题。但**多个线程**共享**多个变量**时，指令重排序的情况就很复杂了。线程是独立的，无法确保另一个线程的重排序会不会影响。举个简单的例子，方便理解：

```kotlin
var value: Int = 0;
var flag: Boolean = false;
​
fun init() {
	value = 8;
	flag = true;
}
​
fun getValue() {
	if (flag) {
		println(value);
	}
}


fun main() {
	// thread 1 可能会先执行 flag = true，后执行 value = 8
	thread { init(); }
	// 在这钟情况下，thread 2 则有可能 print 0;
	thread { getValue() }
}
```

如果没有重排序，因为我们知道线程就算是抢占的，交错执行。但也不会造成 `print`
0 的情况，因为赋值 `value = 8` 是**原子性**（下文介绍）。

2 个线程，2 个共享变量，代码非常简单，却已经快让大脑宕机。实际代码会复杂的多，可见编译器和 CPU 很难确保**重排序**优化在**多线程多共享**的情况下不会出现异外结果。就像这个理论不该出现的 print 0，及时我们知道线程交错执行，我们阅读并人脑编译了代码可能的执行过程，但因为指令重排序的存在，一切变得混沌。

## 操作原子性

## Draft....

这就和一个耳熟能详的特性——「**原子性**」有关了，看一个简单例子就能知道数据一致性不能完全解决线程安全问题的原因。

```kotlin
lateinit var flag: Boolean

// run in A Thread
fun aThread {
    flag = true
    printLn("just do someting and then")
    if(flag) {
	    printLn("when can i do ?")
	}
}

// run in B Thread
fun bThread {
	flag = false
}
```

假设 `aThread` 与 `bTread` 并发执行。先执行到了 `aThread` 的 `just do something and then`，这时触发中断，`bThread` 抢到控制权开始执行，将 `flag` 设为 `false`。导致 `aThread` 本该执行的 `when can i do` 跑不了。

可以看出 `flag` 数据是一致性了，但算法交替运行还是会发生问题。怎么解决例子中的问题？我们需要让 `aThread` 的执行不可被打断。即要么一次执行完 `aThread` 这个方法，要么就不要执行。这个特性就是**原子性**了，叫这个名字是因为不可打断的操作和原子不可分割的特性很像。

### 操作原子性

## 并发编程的一些最佳实践

调度方式和并发模型没有很强的关联关系，调度方式在于是否有主动挂起，并发模型在于同步/异步，阻塞/非阻塞的排列组合。不讨论“回字的四种写法“了，只是

### 合适的“同步”

说好的并发呢，怎么扯起同步来了 👿️”。没办法，要想实现原子性，只能靠一些手段，这些手段会造成同步的效果，`java` 作者在他的书中写过：

> 如果当多个线程访问同一个可变的状态变量时没有使用合适的同步，那么程序就会出现错误。有三种方式可以修复该问题：
>
> - 不在线程之间共享该状态变量
> - 将该状态变量修改为不可变的变量
> - 再访问该状态变量时使用同步

第一种办法属于一刀切，很有效但适用度不高。第二种属于函数式编程思想，设计使用起来不比并发编程简单。第三种就是有不可分割特性的同步操作了。实现形式上的原子性，一般就是锁了。不过不聊锁，先聊聊异步回调。

## 参考

- [并发之痛 Thread，Goroutine，Actor](https://jolestar.com/parallel-programming-model-thread-goroutine-actor/)

[^注：顺序性]: 可能会对 `rx` 的顺序性提出质疑，这里非指过程式一样的代码的编写顺序，例如容易理解的协程的顺序性，而是“可以较为容易”的预测代码执行的顺序。例如 `rx` 的 `obserable.flatmap().reduce().publishOn().map().tap()` 例子，还是可以预测出这段代码的整体顺序性的，只是操作符联合起来会很复杂，让人难以理解，不过还是可以说 `rx` 是有一定顺序性的，毕竟本质上是一个流处理，流的流转过程就是顺序。
[^注：单线程并行]: 如果不把异步 IO 看作一个特殊的“线程”，那将 IO 读写操作交由内核调度，注册回调后继续干活，变相实现了一个线程逻辑计算的同时，其它 IO 硬件也正在读写数据（如网卡），实现并行处理：一个 IO 硬件，一个 CPU。虽然多数场景我们都是要挂起线程，等待 IO 硬件响应的。再展开就是 IO 模型的话题了，本文不过多讨论，不过也可以看出 IO 模型与并发编程的关系密不可分。
